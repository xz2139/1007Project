{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import unicodedata\n",
    "import torch.nn.utils.rnn as rnn\n",
    "#set a binary to represent whether use gpu\n",
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load data\n",
    "data =open('news-headline.txt','r',encoding='utf-8').readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lower case and remove non-vocab letters\n",
    "def normalize(string):\n",
    "    string = string.lower().strip()\n",
    "    string = re.sub(r\"([,.!?])\", r\" \\1 \", string)\n",
    "    string = re.sub(r\"[^a-zA-Z,.!?]+\", r\" \", string)\n",
    "    string = re.sub(r\"\\s+\", r\" \", string).strip()\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split each pair of data into words\n",
    "input_text=[]\n",
    "output_text=[]\n",
    "for pairs in data:\n",
    "    try:\n",
    "        target_r,input_r = pairs[:-1].split('\\t')\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    if input_r.strip()==\"\" or target_r.strip()==\"\": \n",
    "        continue\n",
    "    \n",
    "    input_n = normalize(input_r).split()[:120]\n",
    "    target_n = normalize(target_r).split()\n",
    "    if len(input_n)>=1 and len(target_n)>=1:\n",
    "        \n",
    "        input_text.append(input_n)\n",
    "        output_text.append(target_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# count number of words appear in input and output total\n",
    "# create dictionary to convert each word to a index\n",
    "flatten = lambda l: [i for s in l for i in s]\n",
    "\n",
    "X_all=[i for s in input_text for i in s]\n",
    "Y_all=[i for s in output_text for i in s]\n",
    "\n",
    "\n",
    "input_vocabs = list(set(flatten(input_text)))\n",
    "target_vocabs = list(set(flatten(output_text)))\n",
    "\n",
    "input2index = {'<PAD>':0,'<UNK>':1,'<SOS>':2,'<EOS>':3}\n",
    "for i in input_vocabs:\n",
    "    if i not in input2index.keys():\n",
    "        input2index[i]=len(input2index)\n",
    "        \n",
    "index2input = {v:k for k,v in input2index.items()}\n",
    "\n",
    "target2index = {'<PAD>':0,'<UNK>':1,'<SOS>':2,'<EOS>':3}\n",
    "for i in target_vocabs:\n",
    "    if i not in target2index.keys():\n",
    "        target2index[i]=len(target2index)\n",
    "index2target = {v:k for k,v in target2index.items()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if the sequence is in index, convert it to a tensor, if not, assign unknown character in it\n",
    "def to_variable(seq, to_index):\n",
    "    idxs = list(map(lambda w: to_index[w] if w in to_index.keys() else to_index[\"<UNK>\"], seq))\n",
    "    if use_gpu:    \n",
    "        return Variable(torch.cuda.LongTensor(idxs))\n",
    "    else: torch.LongTensor\n",
    "    return Variable(torch.LongTensor(idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#prepare the data\n",
    "x_prep,y_prep=[],[]\n",
    "\n",
    "for so,ta in zip(input_text,output_text):\n",
    "    x_prep.append(to_variable(so+['<EOS>'],input2index).view(1,-1))\n",
    "    y_prep.append(to_variable(ta+['<EOS>'],target2index).view(1,-1))\n",
    "    \n",
    "train_data = list(zip(x_prep,y_prep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#open numberbatch file\n",
    "numberbatch=open('numberbatch-en.txt','r',encoding='utf-8').readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create embbeding matrix\n",
    "embeddings_index = {}\n",
    "for line in numberbatch:\n",
    "    vector = line.split(' ')\n",
    "    word = vector[0]\n",
    "    embedding = np.asarray(vector[1:], dtype='float32')\n",
    "    embeddings_index[word] = embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dimension is 300 as the vector length are 300 in number batch\n",
    "embedding_dim=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create the embbeding for input\n",
    "input_embedding_matrix = np.zeros(((len(input2index)), embedding_dim))\n",
    "for word,i in input2index.items():\n",
    "    if word in embeddings_index:\n",
    "        input_embedding_matrix[i] = embeddings_index[word]\n",
    "    else:\n",
    "        new_embedding = np.array(np.random.uniform(-1.0, 1.0, embedding_dim))\n",
    "        embeddings_index[word] = new_embedding\n",
    "        input_embedding_matrix[i] = new_embedding\n",
    "        \n",
    "#save if needed        \n",
    "\n",
    "#np.save('input_embedding_matrix.npy',input_embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#input_embedding_matrix=np.load('batch/final_input_embedding_matrix.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create the embbeding for output\n",
    "output_embedding_matrix = np.zeros((len(target2index), embedding_dim))\n",
    "for word,i in target2index.items():\n",
    "    if word in embeddings_index:\n",
    "        output_embedding_matrix[i] = embeddings_index[word]\n",
    "    else:\n",
    "        new_embedding = np.array(np.random.uniform(-1.0, 1.0, embedding_dim))\n",
    "        embeddings_index[word] = new_embedding\n",
    "        output_embedding_matrix[i] = new_embedding\n",
    "        \n",
    "#save if needed\n",
    "#np.save('output_embedding_matrix.npy',output_embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#output_embedding_matrix=np.load('batch/final_output_embedding_matrix.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define encoder\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size,hidden_size, layers):\n",
    "        super(Encoder, self).__init__()      \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.layers = layers        \n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        #load our embedding\n",
    "        self.embedding.weight.data.copy_(torch.from_numpy(input_embedding_matrix)) \n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size, layers, batch_first=True,bidirectional=True)\n",
    "    \n",
    "    def init_hidden(self,inputs):\n",
    "        hidden = (Variable(torch.zeros(self.layers*2,inputs.size(0),self.hidden_size)),Variable(torch.zeros(self.layers*2,inputs.size(0),self.hidden_size)))\n",
    "        if use_gpu:\n",
    "            return (hidden[0].cuda(), hidden[1].cuda())                \n",
    "        else: return hidden\n",
    "    \n",
    "    def init_weight(self):\n",
    "        #normalize weights\n",
    "        self.embedding.weight = nn.init.xavier_uniform(self.embedding.weight)\n",
    "        self.lstm.weight_hh_l0 = nn.init.xavier_uniform(self.lstm.weight_hh_l0)\n",
    "        self.lstm.weight_ih_l0 = nn.init.xavier_uniform(self.lstm.weight_ih_l0)\n",
    "    \n",
    "    def forward(self, inputs, input_lengths):\n",
    "        hidden = self.init_hidden(inputs)        \n",
    "        embedded = self.embedding(inputs)\n",
    "        packed = rnn.pack_padded_sequence(embedded, input_lengths,batch_first=True)\n",
    "        outputs, hidden = self.lstm(packed, hidden)\n",
    "        outputs, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(outputs,batch_first=True)                \n",
    "        hidden=hidden[0]\n",
    "        hidden = hidden[-2:]\n",
    "        return outputs, torch.cat(hidden,1).unsqueeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define decoder\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, layers, dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.layers = layers\n",
    "        #load embbeddings\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.embedding.weight.data.copy_(torch.from_numpy(output_embedding_matrix)) \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.lstm = nn.LSTM(embedding_size+hidden_size, hidden_size, layers,batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size*2, input_size)\n",
    "        self.attn = nn.Linear(self.hidden_size,self.hidden_size)\n",
    "    \n",
    "    def init_hidden(self,inputs):\n",
    "        hidden = (Variable(torch.zeros(self.layers,inputs.size(0),self.hidden_size)),Variable(torch.zeros(self.layers,inputs.size(0),self.hidden_size)))\n",
    "        if use_gpu:\n",
    "            return (hidden[0].cuda(), hidden[1].cuda())\n",
    "        else: return hidden    \n",
    "    \n",
    "    def init_weight(self):\n",
    "        #normalize weights\n",
    "        self.embedding.weight = nn.init.xavier_uniform(self.embedding.weight)\n",
    "        self.lstm.weight_hh_l0 = nn.init.xavier_uniform(self.lstm.weight_hh_l0)\n",
    "        self.lstm.weight_ih_l0 = nn.init.xavier_uniform(self.lstm.weight_ih_l0)\n",
    "        self.linear.weight = nn.init.xavier_uniform(self.linear.weight)\n",
    "        self.attn.weight = nn.init.xavier_uniform(self.attn.weight)\n",
    "    \n",
    "    def Attention(self, hidden, encoder_outputs, encoder_maskings): \n",
    "        #define attention\n",
    "        hidden = hidden[0].unsqueeze(2)        \n",
    "        batch_size = encoder_outputs.size(0) \n",
    "        length = encoder_outputs.size(1) \n",
    "        energies = self.attn(encoder_outputs.contiguous().view(batch_size*length,-1)) \n",
    "        energies = energies.view(batch_size,length,-1)\n",
    "        attn_energies = energies.bmm(hidden).squeeze(2)         \n",
    "        alpha = F.softmax(attn_energies) \n",
    "        alpha = alpha.unsqueeze(1) \n",
    "        context = alpha.bmm(encoder_outputs)         \n",
    "        return context, alpha   \n",
    "    \n",
    "    def forward(self,inputs,encode_hidden,max_length,encoder_outputs,encoder_maskings,is_training=False):\n",
    "        embedded = self.embedding(inputs)\n",
    "        hidden = self.init_hidden(inputs)\n",
    "        if is_training:\n",
    "            embedded = self.dropout(embedded)\n",
    "        decode=[]\n",
    "        for i in range(max_length):\n",
    "            output, hidden = self.lstm(torch.cat((embedded,encode_hidden),2), hidden) \n",
    "            concated = torch.cat((hidden[0],encode_hidden.transpose(0,1)),2) \n",
    "            score = self.linear(concated.squeeze(0))\n",
    "            softmaxed = F.log_softmax(score)\n",
    "            decode.append(softmaxed)\n",
    "            decoded = softmaxed.max(1)[1]\n",
    "            embedded = self.embedding(decoded).unsqueeze(1)  \n",
    "            if is_training:\n",
    "                embedded = self.dropout(embedded)\n",
    "            context, alpha = self.Attention(hidden[0], encoder_outputs,encoder_maskings)\n",
    "            \n",
    "        scores = torch.cat(decode,1)\n",
    "        return scores.view(inputs.size(0)*max_length,-1)\n",
    "\n",
    "    #this is for evaluate\n",
    "    def decode(self,context,encoder_outputs):\n",
    "        if use_gpu:\n",
    "            start_decode = Variable(torch.cuda.LongTensor([[target2index['<SOS>']]*1])).transpose(0,1)\n",
    "        else: start_decode = Variable(torch.LongTensor([[target2index['<SOS>']]*1])).transpose(0,1)\n",
    "        embedded = self.embedding(start_decode)\n",
    "        hidden = self.init_hidden(start_decode)\n",
    "        decodes=[]\n",
    "        attentions=[]\n",
    "        decoded = embedded\n",
    "        while decoded.data.tolist()[0]!=target2index['<EOS>']:\n",
    "            output, hidden = self.lstm(torch.cat((embedded,context),2), hidden) \n",
    "            concated = torch.cat((hidden[0],context.transpose(0,1)),2) \n",
    "            score = self.linear(concated.squeeze(0))\n",
    "            softmaxed = F.log_softmax(score)\n",
    "            decodes.append(softmaxed)\n",
    "            decoded = softmaxed.max(1)[1]\n",
    "            embedded = self.embedding(decoded).unsqueeze(1) \n",
    "            context, alpha = self.Attention(hidden[0], encoder_outputs,None)\n",
    "            attentions.append(alpha.squeeze(1))\n",
    "        \n",
    "        return torch.cat(decodes).max(1)[1], torch.cat(attentions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define hyper parameters\n",
    "epochs=1000\n",
    "batch_size = 64\n",
    "embedding_size = 300\n",
    "hidden_size = 512\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initialize model\n",
    "encoder = Encoder(len(input2index),embedding_size,hidden_size,layers=3)\n",
    "decoder = Decoder(len(target2index),embedding_size,hidden_size*2,layers=1,dropout=0.5)\n",
    "encoder.init_weight()\n",
    "decoder.init_weight()\n",
    "\n",
    "if use_gpu:\n",
    "    encoder = encoder.cuda()\n",
    "    decoder = decoder.cuda()\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss(ignore_index=0)\n",
    "enc_optimizer = optim.Adam(encoder.parameters(),lr=learning_rate)\n",
    "dec_optimizer = optim.Adam(decoder.parameters(),lr=learning_rate*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this is for saving the model\n",
    "#the size is 1.5GB, so be careful\n",
    "def save_checkpoint(state,filename='lstmnewscheckpoint.tar'):\n",
    "    torch.save(state, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#break into batches,this is exceptionally usefull when run on hpc\n",
    "def getBatch(batch_size,traindata):\n",
    "    random.shuffle(traindata)\n",
    "    start=0\n",
    "    end=batch_size\n",
    "    n=len(traindata)\n",
    "    while end < n:\n",
    "        batch = traindata[start:end]\n",
    "        temp = end\n",
    "        end+=batch_size\n",
    "        start = temp\n",
    "        yield batch\n",
    "    \n",
    "    if end >= n:\n",
    "        batch = traindata[start:]\n",
    "        yield batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pad each input to make the size constant for each batch\n",
    "def pad_to_batch(batch,input2index,target2index):\n",
    "    \n",
    "    sorted_batch = sorted(batch, key=lambda b:b[0].size(1),reverse=True) \n",
    "    x,y = list(zip(*sorted_batch))\n",
    "    inputmax = max([item.size(1) for item in x])\n",
    "    outputmax = max([item.size(1) for item in y])\n",
    "    x_paddeds,y_paddeds=[],[]\n",
    "    for i in range(len(batch)):\n",
    "        if x[i].size(1)<inputmax:\n",
    "            if use_gpu:\n",
    "                pads=Variable(torch.cuda.LongTensor([input2index['<PAD>']]*(inputmax-x[i].size(1))))\n",
    "            else: pads=Variable(torch.LongTensor([input2index['<PAD>']]*(inputmax-x[i].size(1))))\n",
    "            x_padded=torch.cat([x[i],pads.view(1,-1)],1)\n",
    "            x_paddeds.append(x_padded)\n",
    "        else:\n",
    "            x_paddeds.append(x[i])\n",
    "        if y[i].size(1)<outputmax:\n",
    "            if use_gpu:\n",
    "                pads=Variable(torch.cuda.LongTensor([target2index['<PAD>']]*(outputmax-y[i].size(1))))\n",
    "            else: pads=Variable(torch.LongTensor([target2index['<PAD>']]*(outputmax-y[i].size(1))))\n",
    "            y_padded=torch.cat([y[i],pads.view(1,-1)],1)\n",
    "            y_paddeds.append(y_padded)\n",
    "        else:\n",
    "            y_paddeds.append(y[i])\n",
    "        \n",
    "    input_variable = torch.cat(x_paddeds)\n",
    "    target_variable = torch.cat(y_paddeds)\n",
    "    input_length=[]\n",
    "    target_length=[]\n",
    "    for i in input_variable:\n",
    "        input_length.append(list(map(lambda a: a ==0, i.data)).count(False))\n",
    "    for i in target_variable:\n",
    "        target_length.append(list(map(lambda a: a ==0, i.data)).count(False))\n",
    "          \n",
    "    return input_variable, target_variable, input_length, target_length\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We Trained this on GPU, it will be really slow if just use cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    losses=[]\n",
    "    for i,batch in enumerate(getBatch(batch_size,train_data)):\n",
    "        inputs,targets,input_lengths,target_lengths = pad_to_batch(batch,input2index,target2index) \n",
    "        if use_gpu:\n",
    "            has_value=[Variable(torch.cuda.ByteTensor(tuple(map(lambda s: s ==0, t.data)))) for t in inputs]\n",
    "        else:\n",
    "            has_value=[Variable(torch.ByteTensor(tuple(map(lambda s: s ==0, t.data)))) for t in inputs]\n",
    "            \n",
    "        masks = torch.cat(has_value).view(inputs.size(0),-1)\n",
    "        \n",
    "        if use_gpu:\n",
    "            start_decode = Variable(torch.cuda.LongTensor([[target2index['<SOS>']]*targets.size(0)])).transpose(0,1)\n",
    "        else:\n",
    "            start_decode = Variable(torch.LongTensor([[target2index['<SOS>']]*targets.size(0)])).transpose(0,1)\n",
    "        encoder.zero_grad()\n",
    "        decoder.zero_grad()\n",
    "        output, encode_hidden = encoder(inputs,input_lengths)\n",
    "        predict_prob = decoder(start_decode,encode_hidden, targets.size(1), output, masks, True)\n",
    "                                \n",
    "        loss = loss_function(predict_prob,targets.view(-1))\n",
    "        losses.append(loss.data.tolist()[0])\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm(encoder.parameters(), 50.0) \n",
    "        torch.nn.utils.clip_grad_norm(decoder.parameters(), 50.0) \n",
    "        enc_optimizer.step()\n",
    "        dec_optimizer.step()\n",
    "        print(loss)\n",
    "###comment out this part if don't want to save output\n",
    "    save_checkpoint({'encoder_dict': encoder.state_dict(),'decoder_dict': decoder.state_dict(),'enc_optimizer' : enc_optimizer.state_dict(),'dec_optimizer' : dec_optimizer.state_dict()})\n",
    "    with open('lstmnewsmeanloss.txt', 'a') as f:\n",
    "        print(np.mean(losses), file=f)\n",
    "    with open('lstmnewsloss_v2.txt', 'a') as f:\n",
    "        print('losses', file=f)\n",
    "        print(losses, file=f)\n",
    "    with open('finalloss.txt', 'a') as f:\n",
    "        print(\"mean_loss : %0.2f\" %np.mean(losses),file=f)\n",
    "####\n",
    "    losses=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##This is for loading the saved model\n",
    "# checkpoint = torch.load('finalcheckpoint.tar', map_location={'cuda:0': 'cpu'})\n",
    "# encoder.load_state_dict(checkpoint['encoder_dict'])\n",
    "# decoder.load_state_dict(checkpoint['decoder_dict'])\n",
    "# enc_optimizer.load_state_dict(checkpoint['enc_optimizer'])\n",
    "# dec_optimizer.load_state_dict(checkpoint['dec_optimizer'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we can randomly choose data for evaluation\n",
    "\n",
    "def evaluate(traindata):\n",
    "    test = random.choice(traindata)\n",
    "    testinput = test[0]\n",
    "    testoutput = test[1]\n",
    "\n",
    "    output, hidden = encoder(testinput,[testinput.size(1)])\n",
    "    pred,_ = decoder.decode(hidden,output)\n",
    "\n",
    "    testinput = [index2input[i] for i in testinput.data.tolist()[0]]\n",
    "    pred = [index2target[i] for i in pred.data.tolist()]\n",
    "\n",
    "    print('Input : ',' '.join([i for i in testinput if i not in ['<EOS>']]))\n",
    "    print('Target : ',' '.join([index2target[i] for i in testoutput.data.tolist()[0] if i not in [2,3]]))\n",
    "    print('Prediction : ',' '.join([i for i in pred if i not in ['<EOS>']]))\n",
    "\n",
    "evaluate(train_data)  \n",
    "evaluate(train_data) \n",
    "evaluate(train_data) \n",
    "evaluate(train_data) \n",
    "evaluate(train_data) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
